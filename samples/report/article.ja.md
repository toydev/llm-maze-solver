---
title: ローカルLLMの2D空間認識能力 ― プロンプト戦略の比較
tags: LLM Ollama ローカルLLM プロンプトエンジニアリング gpt-oss
---

# 1. はじめに

2025-2026 年末年始、私の GPU は LLM に占拠されていましたがやっと解放されました（歓喜）。

ローカル LLM（gpt-oss:20b）の**2D 空間認識能力**を迷路を題材に調査しました。

- 動機: LLMに自律的な動きをさせるために空間がどう見えているか知りたい
- 方法: 全マス × 1マスごとに「次どっち？」と構造化出力で問う
- プロンプト: どんなプロンプトが良いかわからないので複数試した
- ソース・実験結果: [GitHub](https://github.com/toydev/llm-maze-solver/tree/article-2026-01) で公開

結果、私が最初に考えたプロンプトが最悪でした（白目）。

## 主な発見

- **ローカル LLM でも 2D 空間認識は可能** - gpt-oss:20b で十分な正解率を達成
- **プロンプト戦略で大きな差** - 応答時間に数倍の開き

---

# 2. 実験設定

## 実行環境

- OS: Windows 11 / WSL2 (Ubuntu)
- CPU: AMD Ryzen 7 7700
- GPU: GeForce RTX 4070 (12GB VRAM)
- LLM実行: Ollama
- 実験コード: Node.js + TypeScript + @langchain/ollama 1.1.0

## モデル

[gpt-oss:20b](https://ollama.com/library/gpt-oss) を使用。推奨VRAMは16GBだが、12GB環境でもCPUオフロード併用で動作する（24% CPU / 76% GPU）。

## プロンプト戦略

4つの戦略を比較（各リンク先でプロンプト出力例を確認できる）:

**[simple](https://github.com/toydev/llm-maze-solver/blob/article-2026-01/src/prompt/strategies/simple.test.ts)** - 迷路を文字で視覚化
```
#####
#S#G#
# # #
#   #
#####
```

**[matrix](https://github.com/toydev/llm-maze-solver/blob/article-2026-01/src/prompt/strategies/matrix.test.ts)** - 壁/通路を二値行列で表現
```
[[1,1,1,1,1],[1,0,1,0,1],[1,0,1,0,1],[1,0,0,0,1],[1,1,1,1,1]]
```

**[list](https://github.com/toydev/llm-maze-solver/blob/article-2026-01/src/prompt/strategies/list.test.ts)** - 歩ける座標のリスト
```
["(1,1)","(3,1)","(1,2)","(3,2)","(1,3)","(2,3)","(3,3)"]
```

**[graph](https://github.com/toydev/llm-maze-solver/blob/article-2026-01/src/prompt/strategies/graph.test.ts)** - 隣接リスト形式
```
{"1,1":["1,2"],"1,2":["1,1","1,3"],"1,3":["1,2","2,3"],...}
```

## 迷路

4サイズ（5x5〜15x15）× 2カテゴリの迷路を使用（[迷路一覧](https://github.com/toydev/llm-maze-solver/tree/article-2026-01/mazes)）:

**corridor（通路型）** - 壁に囲まれた通路

![corridor](11x11_corridor_straight.png) ![corridor](11x11_corridor_branch.png) ![corridor](11x11_corridor_dead-end.png) ![corridor](11x11_corridor_loop.png) ![corridor](11x11_corridor_spiral.png)

**open（広場型）** - 広い空間に障害物

![open](11x11_open_empty.png) ![open](11x11_open_pass.png) ![open](11x11_open_detour.png)

※ 黒=壁、白=通路、緑=Start、赤=Goal

## 履歴オプション

履歴とは、現在のマスに至るまでの移動経路のこと（例: `(1,1) -> (1,2) -> (2,2)`）。

- あり: 履歴をプロンプトに含める
- なし: 履歴をプロンプトに含めない

## 評価方法

迷路の全マスについて、1マスずつ「次にどの方向へ進むべきか」を問い、成否と応答時間を記録する。

正解の定義は、**ゴールに近づく方向であれば正解**とする。最短ルートである必要はない。

---

# 3. 実験結果

各組み合わせの実行回数は基本1回。傾向を見るための参考データとして捉えてほしい。

詳細データは[リポジトリ](https://github.com/toydev/llm-maze-solver/tree/article-2026-01)で公開している。

## スケール検証

代表的な迷路（corridor_straight / open_empty）で全サイズ × 全戦略を試した結果（履歴ありのみ）。

**正解率（%）**

| サイズ | simple | matrix | list | graph |
|--------|--------|--------|------|-------|
| 5x5 | 100 | 100 | 100 | 100 |
| 7x7 | 97 | 100 | 100 | 100 |
| 11x11 | 82 | 96 | 98 | 95 |
| 15x15 | - | - | 95 | 89 |

**応答時間（秒/マス）**

| サイズ | simple | matrix | list | graph |
|--------|--------|--------|------|-------|
| 5x5 | 29 | 19 | 12 | 12 |
| 7x7 | 77 | 31 | 16 | 17 |
| 11x11 | 313 | 75 | 31 | 64 |
| 15x15 | - | - | 41 | 190 |

※ 15x15 の matrix / simple は時間的に断念。

**list が最速かつ高精度**。サイズが大きくなるほど差が開く。simple は 11x11 で 313 秒/マス（5分以上）まで悪化した。

## 履歴の効果

11x11 の list 戦略で履歴の有無を比較（カテゴリ内の平均値）。

**正解率（%）**

| カテゴリ | 履歴なし | 履歴あり |
|----------|----------|----------|
| corridor（通路型） | 82 | 86 |
| open（広場型） | 99 | 100 |

**応答時間（秒/マス）**

| カテゴリ | 履歴なし | 履歴あり |
|----------|----------|----------|
| corridor（通路型） | 230 | 110 |
| open（広場型） | 29 | 26 |

corridor 系では**履歴ありで約2倍速い**。open 系はほぼ変わらない。

---

# 4. 結論

## gpt-oss:20b の 2D 空間認識能力

gpt-oss:20b は迷路を攻略できるだけの 2D 空間認識能力を持っている。
正解率 80% 以上なら最短ルートの約 1.5 倍以内でゴールできる水準だ。

応答時間も list 戦略なら 11x11 で 30 秒/マス程度。
リアルタイム処理は無理でも、遊び用途ならローカル LLM で十分現実的な時間で処理できる。

gpt-oss:20b の比較対象として参考までに限られた時間の中ではあるが以下の２つを試した。

| モデル | 感触 |
| --- | --- |
| gemma3:12b | 正解率 50% 程度で実用にならなかった。|
| deepseek-r1:14b | gpt-oss:20b 程ではないが良い感触を得ることができた。|

gpt-oss:20b と deepseek-r1:14b の共通である Reasoning 機能が大きな役割を果たしているのではないかと考えている。

私の環境で deepseek-r1:14b は 100% GPU で動かすことができるが、76% GPU の gpt-oss:20b の方が早く精度も良さそうであったのには驚かされた。

## list + 履歴あり = 最強

プロンプト戦略によって正解率・応答時間が大きく変わることがわかった。

私が最初に考えた戦略は simple であり、人間的にはわかりやすいと思ったが最悪だった。

次に試したのが探索用構造化データの graph である。
小サイズの迷路に対して simple より早く、私はこれに希望を見出したが、サイズが大きくなるにつれて応答時間が悪化する様子を見て絶望した。
隣接情報の増加の結果だと考えている。

matrix は simple を構造化データにしたものだがあまり良い結果を得ることができなかった。

人間が見ても迷路の構造が理解できない座標リストの list が最強になるとは全く思っていなかった。

履歴については、次に進む道を決めるにあたって、ここまでどう来たのかという情報が単純に役立っているのではないかと考えている。
corridor（通路型）ではそれがすごく役に立っている。
一方で処理トークンが増えることも意味してしまうので、直近の数歩分だけを与えるだけで効果があるなら、節約を考えることもできるかもしれない。

---

この記事とコードは Claude Code との協業で作成した。
実験対象となる迷路の作成も Claude Code に依頼したが、simple 形式で正確に作成するのが苦手なようで、作ってもらったものを私がかなり手作業で調整した。
Claude Code ですら苦手な simple 形式、ローカル LLM が苦手なのも無理はないのかもしれない。

ソースと実験データは [GitHub](https://github.com/toydev/llm-maze-solver/tree/article-2026-01) で公開している。興味があれば試してみてほしい。
